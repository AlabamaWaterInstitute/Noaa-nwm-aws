{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3b4d424-9cfd-457e-ad37-f63a336d283e",
   "metadata": {},
   "source": [
    "## FSSPEC download for NWM RouteLink file for developing topologic relationships\n",
    "This notebook demonstrates accessing the National Water Model (NWM) topological definition of the NWM channel routing simulation. The methods applied here utilize Zarr and FSSpec to retrieve the header for the file and then only the topology-definining fields: \"link\" and \"to\". Building the dataframe directly from these elements in the file from the web saves a 200Mb download and takes quite a bit less time than when obtaining the full file and operating from a local storage resource.\n",
    "\n",
    "The key here is to note which operations take a long time: \n",
    "* The initial `SingleHdf5ToZarr` step is about 1 second\n",
    "* The `.translate()` operation (inline in our example) is about 8 seconds\n",
    "* Opening the dataset from the translated .json object is only a few milliseconds\n",
    "* reading the \"to\" and \"from\" attributes into a pandas dataframe is 11 seconds\n",
    "\n",
    "That last step would be a lot longer if all variables were downloaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4949ca1b-3b70-4b6b-9ef1-bd1f5cf13ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import xarray as xr\n",
    "from kerchunk.hdf import SingleHdf5ToZarr\n",
    "\n",
    "fs = fsspec.filesystem(\"http\")\n",
    "\n",
    "rl_nwm_url = \"https://www.nco.ncep.noaa.gov/pmb/codes/nwprod/nwm.v2.2.0/parm/DOMAIN_WCOSS_Names/RouteLink_CONUS.nc\"\n",
    "with fs.open(rl_nwm_url) as f:\n",
    "    %time    rl_t = SingleHdf5ToZarr(f, rl_nwm_url, inline_threshold=0).translate()\n",
    "    \n",
    "    # Key example here: \n",
    "    # https://fsspec.github.io/kerchunk/test_example.html\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c49383-99e6-4968-87ee-1a1004406752",
   "metadata": {},
   "source": [
    "The `kerchunk`-ing example that we started with had a number of other parameters... \n",
    "perhaps some might be reintroduced to make the data access even speedier!\n",
    "e.g., ...\n",
    "```py\n",
    "fs = fsspec.filesystem('ftp', host=\"https://www.nco.ncep.noaa.gov/pmb\")\n",
    "\n",
    "with fs.open(rl_nwm_url, mode='rb', anon=True, default_fill_cache=False, default_cache_type='first') as f:\n",
    "```\n",
    " ...\n",
    " \n",
    "One thing that I specifically explored was the size of the `inline_threshold` setting. Smaller values definitely provided better results, though not a massivie improvement -- 9 seconds overall vs. 11 or so. \n",
    "```py\n",
    "    %time    rl_h5_t = SingleHdf5ToZarr(f, rl_nwm_url).translate() # 11.1 s\n",
    "    %time    rl_h5_t = SingleHdf5ToZarr(f, rl_nwm_url, inline_threshold=30000).translate() # 11.3 s\n",
    "    %time    rl_h5_t = SingleHdf5ToZarr(f, rl_nwm_url, inline_threshold=300).translate() # 11.2 s\n",
    "    %time    rl_h5_t = SingleHdf5ToZarr(f, rl_nwm_url, inline_threshold=10).translate() # 11.3 s\n",
    "    %time    rl_h5_t = SingleHdf5ToZarr(f, rl_nwm_url, inline_threshold=2).translate() # 9.8 s\n",
    "    %time    rl_h5_t = SingleHdf5ToZarr(f, rl_nwm_url, inline_threshold=1).translate() # 9.85 s\n",
    "    %time    rl_h5_t = SingleHdf5ToZarr(f, rl_nwm_url, inline_threshold=0).translate() # 9.83 s\n",
    "    %time    rl_h5_t = SingleHdf5ToZarr(f, rl_nwm_url, inline_threshold=-1).translate() # 9.54 s\n",
    "```\n",
    "Inlining the `.translate()` call vs. splitting seemed to be about equal, with inlining having the additional advantage of omitting the unused intermediate output. \n",
    "```py\n",
    "    %time    rl_h5 = SingleHdf5ToZarr(f, rl_nwm_url, inline_threshold=0)\n",
    "    %time    rl_t = rl_h5.translate() # This translate MUST happen inside the context block\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29ee768-6113-4b66-9e57-94b8d08cdaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_args = {\n",
    "    \"consolidated\": False,\n",
    "    \"storage_options\": {\n",
    "        \"fo\": rl_t,\n",
    "        # Adding these options returns a properly dimensioned but otherwise null dataframe\n",
    "        # \"remote_protocol\": \"https\",\n",
    "        # \"remote_options\": {'anon':True}\n",
    "    },\n",
    "}\n",
    "%time ds = xr.open_dataset(\"reference://\", engine=\"zarr\", backend_kwargs=backend_args,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4ba8d9-6485-4304-9f73-c05a4dde01ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "subslice = [\n",
    "    \"link\",\n",
    "    \"to\",\n",
    "]\n",
    "%time df = ds[subslice].to_dataframe().astype({\"link\": int, \"to\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d3304-e9b7-4291-be02-9187d09f8250",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341cbf8a-467d-4e98-a380-17bc58922948",
   "metadata": {},
   "source": [
    "## Create a topology\n",
    "With the downloaded Route_Link, we can generate the topology of the CONUS river network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4215cc7b-32b9-4ab5-8a3c-ce4439955c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(\"link\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e3677-e1ba-4f89-b0e8-e094120190ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT Used yet...\n",
    "def build_mask(param_df, mask_file_path, mask_key):\n",
    "    data_mask = nhd_io.read_mask(\n",
    "        mask_file_path,\n",
    "    )\n",
    "\n",
    "    return param_df.filter(data_mask.iloc[:, [mask_key]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5a383-8bbf-45c7-b42f-b647d5511419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nhd_network\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def replace_downstreams(data, downstream_col, terminal_code):\n",
    "    ds0_mask = data[downstream_col] == terminal_code\n",
    "    new_data = data.copy()\n",
    "    new_data.loc[ds0_mask, downstream_col] = ds0_mask.index[ds0_mask]\n",
    "\n",
    "    # Also set negative any nodes in downstream col not in data.index\n",
    "    new_data.loc[~data[downstream_col].isin(data.index), downstream_col] *= -1\n",
    "    return new_data\n",
    "\n",
    "\n",
    "def organize_independent_networks(connections):\n",
    "    rconn = nhd_network.reverse_network(connections)\n",
    "    independent_networks = nhd_network.reachable_network(rconn)\n",
    "    reaches_bytw = {}\n",
    "    for tw, net in independent_networks.items():\n",
    "        path_func = partial(nhd_network.split_at_junction, net)\n",
    "        reaches_bytw[tw] = nhd_network.dfs_decomposition(net, path_func)\n",
    "\n",
    "    return independent_networks, reaches_bytw, rconn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d27c36e-8a46-47ba-800f-3983eed967e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_index()\n",
    "df = replace_downstreams(df, \"to\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46965cfe-b843-4292-a685-3a2b1c7b2c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = nhd_network.extract_connections(df, \"to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6941fb8b-4899-4cfc-8888-97de1be4c0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_networks, reaches_bytw, rconn = organize_independent_networks(connections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7fc989-2d07-44ae-aed0-5f939dda9be7",
   "metadata": {},
   "source": [
    "### So, what?\n",
    "At this point we have a couple of objects representing the U.S. stream network (or another country or region, if you snuck a mask or different base route-link file in there!).\n",
    "* `connections` is a dictionary of each `link` and the `to` downstream link id. All connections that point\n",
    "to a null downstream (i.e., they flow off the map into the ocean or into an interior terminal basin) have\n",
    "been massaged so that they point to an id which is the negative of the last valid segment id.\n",
    "* `rconn` is the reverse dictionary of connections. Unlike the connections DAG which is strictly\n",
    "coalescing, the `rconn` values contain multiple values where junctions split and the value list may\n",
    "contain multiple upstream `link` ids for each of the incoming channels to a junction.\n",
    "* `independent_networks` is a grouping of the rconn dictionary into connections that are related\n",
    "topologically to a single tailwater. THIS IS NOT ORDERED (except by whatever falls out of the original reversal of the connections dictionary.)\n",
    "* `reaches_bytw` is perhaps the most mysterious. It is a topologically ordered list of lists for\n",
    "each tailwater that, if traversed in order, guarantees that each leaf of the tailwater DAG is touched\n",
    "before any downstream junction is traversed.\n",
    "\n",
    "### Example:\n",
    "We can run simple script to find the networks of any given size. We choose a size of 8 so we can diagram things more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5641f379-3c9c-4f30-b4ba-eec6629375f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = independent_networks\n",
    "for k in sorted(d, key=lambda k: len(d[k]), reverse=True):\n",
    "    if len(d[k]) == 8:\n",
    "        print(k, len(d[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c72248c-5d5e-4b2d-8bf9-f4139b70b497",
   "metadata": {},
   "source": [
    "From the list, we choose a random network that has only 8 channel segments, -20427622. \n",
    "If we examine the original dataframe, we can learn the lat-lon coordinates of our segment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179deb7-b80c-4785-b8d8-aa2fbe364c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment = -20427622\n",
    "print(segment, len(independent_networks[segment]))\n",
    "\n",
    "print(\n",
    "    df.loc[-segment]\n",
    ")  # remember, we need the -segment because we've labeled the tailwaters with a dummy downstream terminal value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1930acb-d4a0-4155-b56f-33138c9e3189",
   "metadata": {},
   "source": [
    "... and plot it's position on a map:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60ebf97-cd74-4dac-b410-fdc63603aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "_df = df.loc[[-segment]]\n",
    "_geometry = [Point(xy) for xy in zip(_df[\"lon\"], _df[\"lat\"])]\n",
    "_gdf = GeoDataFrame(_df, geometry=_geometry)\n",
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "_gdf.plot(ax=world.plot(figsize=(10, 6)), marker=\"o\", color=\"red\", markersize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86434f6c-3985-4674-9a64-eec3c366bc12",
   "metadata": {},
   "source": [
    "Or, we can use a slightly more sophisticated map to discover that we have chosen an interior basin near Phoenix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4682056-6a89-4712-ba13-772dfcb4dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# create a map\n",
    "this_map = folium.Map(prefer_canvas=True)\n",
    "\n",
    "\n",
    "def plotDot(point):\n",
    "    \"\"\"input: series that contains a numeric named latitude and a numeric named longitude\n",
    "    this function creates a CircleMarker and adds it to your this_map\"\"\"\n",
    "    folium.CircleMarker(location=[point.lat, point.lon], radius=8, weight=5).add_to(\n",
    "        this_map\n",
    "    )\n",
    "\n",
    "\n",
    "# use df.apply(,axis=1) to \"iterate\" through every row in your dataframe\n",
    "_df.apply(plotDot, axis=1)\n",
    "\n",
    "\n",
    "# Set the zoom to the maximum possible\n",
    "this_map.fit_bounds(this_map.get_bounds())\n",
    "\n",
    "# Save the map to an HTML file\n",
    "this_map.save(\"simple_dot_plot.html\")\n",
    "\n",
    "this_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca039fb-0181-4e93-9000-494aa79a063a",
   "metadata": {},
   "source": [
    "So with that context for our tiny little drainage, we look at the connections and rconn dictionary results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d594fa-c8d7-4850-8756-652a1a4c4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{connections[-segment]} the last item in the DAG points to our tailwater\")\n",
    "print(\n",
    "    f\"{rconn[segment]} ... and the upstream looking connection from the tailwater points to the last element of the DAG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208611c7-2c12-41a4-83ea-3f7e4d048d02",
   "metadata": {},
   "source": [
    "The `independent_networks` dictionary will show us which are the 8 segments in the DAG, each with their corresponding upstream neighbor or neighbors, which looks like the following for our example ...\n",
    "\n",
    "```\n",
    "independent_networks[segment]\n",
    "{20427706: [20429532],\n",
    " 20429540: [],\n",
    " 20427622: [20427704, 20427706],\n",
    " 20429612: [],\n",
    " 20429616: [],\n",
    " 20427704: [20429540],\n",
    " -20427622: [20427622],\n",
    " 20429532: [20429612, 20429616]}\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0d908338-63c8-42fb-bf3f-bb71543e3efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-20427622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{20427706: [20429532],\n",
       " 20429540: [],\n",
       " 20427622: [20427704, 20427706],\n",
       " 20429612: [],\n",
       " 20429616: [],\n",
       " 20427704: [20429540],\n",
       " -20427622: [20427622],\n",
       " 20429532: [20429612, 20429616]}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(segment)\n",
    "independent_networks[segment]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acc9acb-81c7-4438-9c5f-e07847305e50",
   "metadata": {},
   "source": [
    "... and the `reaches_bytw` object gives the order of these in reaches between junctions using DFS ordering only reveresed, to start at the leaves.\n",
    "\n",
    "for our example, this looks like\n",
    "```\n",
    "reaches_bytw[-20427622]\n",
    "\n",
    "[[20429540, 20427704],\n",
    " [20429612],\n",
    " [20429616],\n",
    " [20429532, 20427706],\n",
    " [20427622, -20427622]]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c5711a51-b6a7-4213-8d05-d873fd32737c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-20427622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[20429540, 20427704],\n",
       " [20429612],\n",
       " [20429616],\n",
       " [20429532, 20427706],\n",
       " [20427622, -20427622]]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(segment)\n",
    "reaches_bytw[segment]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac06df78-506e-4931-a936-d482d67a90c1",
   "metadata": {},
   "source": [
    "You'll have to look at this for a minute, but trust me, you can derive the following topological\n",
    "map from those two pieces of information. (Technically, you would only need the `independent_networks`\n",
    "information, but it's nice to get confirmation from the other object.)\n",
    "```\n",
    "upstream...\n",
    "\n",
    "             20429612     20429616\n",
    "                 ├────────────┘\n",
    " 20429540    20429532\n",
    "    │            │\n",
    " 20427704    20427706\n",
    "    ├────────────┘\n",
    " 20427622\n",
    "    │\n",
    "-20427622\n",
    "\n",
    "downstream...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26516738-1e80-416b-9e56-10e9cf846909",
   "metadata": {},
   "source": [
    "We can chain the segment IDs together -- this can be useful for instance if we want to query all IDs in a given basin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5314546e-5e10-4d6a-aee3-908dde341392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20429540,\n",
       " 20427704,\n",
       " 20429612,\n",
       " 20429616,\n",
       " 20429532,\n",
       " 20427706,\n",
       " 20427622,\n",
       " -20427622]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "list(chain(*reaches_bytw[segment]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e9b73e-b76e-432d-8611-a51283199ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
